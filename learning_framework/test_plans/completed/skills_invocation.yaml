# ABOUTME: Test plan for learning how skills get invoked
# ABOUTME: Start simple - we'll add complexity as we learn

feature:
  name: skills_invocation
  description: Understanding how and when skills are automatically invoked
  category: claude-code

# Key questions we want to answer
learning_goals:
  - What triggers skill invocation?
  - How detailed must skill descriptions be?
  - Do keywords in descriptions help?
  - What phrases work reliably?

# Simple hypotheses to test one at a time
hypotheses:
  - id: h1
    statement: "Mentioning the skill name explicitly triggers invocation"
    test_prompts:
      - "Use the test-skill skill to analyze this"  # expect: invoked
      - "Analyze this file"  # expect: not invoked

  - id: h2
    statement: "Keywords from skill description trigger invocation"
    setup_notes: "Create skill with 'analyze', 'review' keywords"
    test_prompts:
      - "Analyze this code"  # expect: invoked
      - "Review this file"  # expect: invoked
      - "Look at this"  # expect: uncertain

  - id: h3
    statement: "Task description match triggers invocation"
    setup_notes: "Create skill that says 'Use when analyzing Python code'"
    test_prompts:
      - "Analyze this Python code"  # expect: invoked
      - "Analyze this JavaScript code"  # expect: uncertain
      - "What does this code do?"  # expect: uncertain

# Notes on manual testing process
testing_process:
  1_setup: |
    Create/modify test skill in tester_workspace/.claude/skills/
    Skills already created:
      - test-skill-minimal: Minimal description ("Does a thing")
      - test-skill-detailed: Keyword-rich description with analyze/review/inspect

  2_test: |
    IMPORTANT: Must run claude FROM the tester_workspace directory!

    cd learning_framework/tester_workspace
    claude

    Then run each test prompt and observe:
    - Did Claude show "Loading skill..." message?
    - Did Claude use the Skill tool?
    - What was Claude's reasoning for using/not using the skill?

  3_record: |
    From learning_framework directory:

    python record_experiment.py \
      --feature skills_invocation \
      --hypothesis "Your hypothesis" \
      --prompt "The exact prompt you used" \
      --expected invoked|not_invoked|uncertain \
      --actual invoked|not_invoked \
      --notes "What you observed"
