# ABOUTME: Test plan for multi-instance Claude orchestration via Agent SDK
# ABOUTME: Based on original vision - autonomous Dev + Tester pattern

feature:
  name: multi_instance_orchestration
  description: Can we orchestrate multiple Claude Code instances for autonomous learning?
  category: agent-sdk

# From original vision (docs/prompt):
# "Can I get Claude Code to operate another instance of Claude Code to do the testing?"
# "One was the dev and the other the tester"
original_questions:
  - Can Agent SDK control multiple Claude Code instances?
  - Can instances communicate via shared files?
  - Can we automate the Dev+Tester learning pattern?
  - What are the limitations?

# From AUTONOMOUS_LEARNING_FRAMEWORK.md:
# Two-Instance Pattern:
# - Dev Instance: Designs tests, analyzes results, updates knowledge
# - Tester Instance: Runs tests, records results, clean environment
architecture_reference: |
  ┌─────────────────────────────────────────────────────────────┐
  │                    Test Orchestrator                        │
  │                  (Python Script)                            │
  │                                                             │
  │  ┌──────────────────────┐      ┌──────────────────────┐   │
  │  │   Dev Instance       │      │   Tester Instance    │   │
  │  │   (Claude Code)      │      │   (Claude Code)      │   │
  │  │                      │      │                      │   │
  │  │  - Design tests      │◄────►│  - Run tests         │   │
  │  │  - Analyze results   │      │  - Record results    │   │
  │  │  - Update knowledge  │      │  - Clean env         │   │
  │  │  - Generate hypotheses│     │  - Restart as needed │   │
  │  └──────────────────────┘      └──────────────────────┘   │
  │           │                              │                  │
  │           ▼                              ▼                  │
  │  ┌────────────────────────────────────────────────────┐   │
  │  │           Shared Filesystem                        │   │
  │  │  - Test plans (YAML)                              │   │
  │  │  - Test results (JSON)                            │   │
  │  │  - Knowledge base (SQLite)                        │   │
  │  └────────────────────────────────────────────────────┘   │
  └─────────────────────────────────────────────────────────────┘

learning_goals:
  - Verify Agent SDK can spawn independent instances
  - Test if instances can work on different directories
  - Validate shared file communication
  - Understand session isolation and state
  - Document practical orchestration patterns

hypotheses:
  - id: h1
    statement: "Agent SDK can create multiple independent sessions"
    evidence_needed:
      - Two ClaudeSDKClient instances running
      - Different cwd for each
      - No cross-contamination of context

  - id: h2
    statement: "Sessions can communicate via shared files"
    evidence_needed:
      - Session A writes file
      - Session B reads file
      - Content correctly shared

  - id: h3
    statement: "Sessions can be coordinated by Python orchestrator"
    evidence_needed:
      - Orchestrator sends to Session A
      - Gets response
      - Uses response to send to Session B
      - Round-trip coordination works

  - id: h4
    statement: "Each session has independent tool permissions"
    evidence_needed:
      - Session A with permissive settings
      - Session B with restrictive settings
      - Each honors its own settings

  - id: h5
    statement: "Full autonomous learning cycle can execute"
    evidence_needed:
      - Dev designs test
      - Tester runs test
      - Results captured
      - Dev analyzes
      - Knowledge updated
      - All without human intervention

experiments:
  - id: dual_session_creation
    hypothesis_id: h1
    description: Create two independent Agent SDK sessions
    setup: |
      dev_options = ClaudeAgentOptions(
          cwd="/path/to/dev_harness",
          add_dirs=["/path/to/dev_harness"],
          permission_mode='acceptEdits'
      )

      tester_options = ClaudeAgentOptions(
          cwd="/path/to/tester_workspace",
          add_dirs=["/path/to/tester_workspace"],
          permission_mode='acceptEdits'
      )
    test:
      - Create both sessions
      - Ask each "Where am I working?"
      - Verify different directories reported
    expected:
      - Both sessions created successfully
      - Each reports correct working directory
      - No interference

  - id: file_communication
    hypothesis_id: h2
    description: Test communication via shared file
    test_steps:
      - Session A writes JSON to shared/message.json
      - Session B reads shared/message.json
      - Verify content matches
    expected:
      - Write succeeds
      - Read succeeds
      - Content matches

  - id: coordinated_prompts
    hypothesis_id: h3
    description: Orchestrator coordinates between sessions
    test_steps:
      - Orchestrator asks Dev "Create a test plan for X"
      - Dev outputs test plan
      - Orchestrator parses response
      - Orchestrator asks Tester "Run this test: [plan]"
      - Tester executes and reports
      - Orchestrator collects results
    expected:
      - Sequential coordination works
      - Responses can be parsed
      - Information passes correctly

  - id: permission_isolation
    hypothesis_id: h4
    description: Verify sessions respect their own permissions
    setup:
      dev_settings: '{"allowed_tools": ["*"]}'
      tester_settings: '{"allowed_tools": ["Read(*)", "Grep(*)"]}'
    test_steps:
      - Dev tries Write - should succeed
      - Tester tries Write - should fail/prompt
    expected:
      - Each session uses its configured permissions
      - No leakage between sessions

  - id: full_learning_cycle
    hypothesis_id: h5
    description: Execute complete autonomous learning cycle
    test_flow:
      - 1: Dev creates test plan YAML
      - 2: Orchestrator configures tester environment
      - 3: Tester runs test scenarios
      - 4: Results written to shared JSON
      - 5: Dev reads results and analyzes
      - 6: Dev updates knowledge base
      - 7: Cycle completes without human intervention
    success_criteria:
      - All steps execute automatically
      - Knowledge base updated with learnings
      - Process can repeat for next hypothesis

success_metrics:
  - "Multi-session orchestration demonstrated"
  - "File-based communication validated"
  - "Permission isolation confirmed"
  - "Full autonomous cycle achieved (or limitations documented)"

testing_process:
  1_validate_api: |
    First, verify Agent SDK supports multiple sessions:

    python -c "
    import asyncio
    from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions

    async def test():
        opt1 = ClaudeAgentOptions(cwd='/tmp/test1')
        opt2 = ClaudeAgentOptions(cwd='/tmp/test2')

        async with ClaudeSDKClient(options=opt1) as c1:
            async with ClaudeSDKClient(options=opt2) as c2:
                # Both active simultaneously?
                pass

    asyncio.run(test())
    "

  2_build_minimal_orchestrator: |
    Create simple Python script that:
    - Creates Dev session
    - Creates Tester session
    - Sends one prompt to each
    - Captures responses

  3_test_communication: |
    Test file-based communication between sessions:
    - Have Dev write a file
    - Have Tester read the same file
    - Verify content

  4_full_cycle_test: |
    Attempt full learning cycle with simple feature:
    - Create test plan for "echo tool"
    - Have Dev design test
    - Have Tester execute
    - Have Dev analyze

notes: |
  This is the KEY gap from the original vision. The autonomous learning
  framework depends on multi-instance orchestration.

  If this works: Full autonomous learning is possible
  If this fails: Need semi-automated approach with human in loop

  Critical Questions from AUTONOMOUS_LEARNING_SPEC.md:
  Q1: Can Agent SDK control multiple Claude Code instances?
  Q2: How to capture skill invocation from transcript?
  Q3: How to measure "bulletproof"?

  The run_experiment.py already works - this plan tests if we can
  have TWO such sessions coordinated by Python.
